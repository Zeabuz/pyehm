{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# JPDA vs JPDA with EHM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we compare the performance of the standard JPDA implementation [1], which exhaustively enumerates all joint hypotheses, to a fast implementation of JPDA, which makes use of Efficient Hypothesis Management (EHM) [2].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate ground truth\n",
    "---------------------\n",
    "As with the [JPDA tutorial](https://stonesoup.readthedocs.io/en/v0.1b6/auto_tutorials/08_JPDATutorial.html), we simulate two targets moving in the\n",
    "positive x, y cartesian plane (intersecting approximately half-way through their transition).\n",
    "We then add truth detections with clutter at each time-step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, \\\n",
    "                                               ConstantVelocity\n",
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.types.detection import TrueDetection\n",
    "from stonesoup.types.detection import Clutter\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "\n",
    "# np.random.seed(1991)\n",
    "\n",
    "truths = set()\n",
    "\n",
    "start_time = datetime.now()\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(0.005),\n",
    "                                                          ConstantVelocity(0.005)])\n",
    "\n",
    "truth = GroundTruthPath([GroundTruthState([0, 1, 0, 1], timestamp=start_time)])\n",
    "for k in range(1, 21):\n",
    "    truth.append(GroundTruthState(\n",
    "        transition_model.function(truth[k-1], noise=True, time_interval=timedelta(seconds=1)),\n",
    "        timestamp=start_time+timedelta(seconds=k)))\n",
    "truths.add(truth)\n",
    "\n",
    "truth = GroundTruthPath([GroundTruthState([0, 1, 20, -1], timestamp=start_time)])\n",
    "for k in range(1, 21):\n",
    "    truth.append(GroundTruthState(\n",
    "        transition_model.function(truth[k-1], noise=True, time_interval=timedelta(seconds=1)),\n",
    "        timestamp=start_time+timedelta(seconds=k)))\n",
    "truths.add(truth)\n",
    "\n",
    "multi_fig = plt.figure(figsize=(10, 12))\n",
    "axm = multi_fig.add_subplot(2, 1, 1)\n",
    "axm.set_xlabel(\"$x$\")\n",
    "axm.set_ylabel(\"$y$\")\n",
    "axm.set_ylim(0, 25)\n",
    "axm.set_xlim(0, 25)\n",
    "axm.set_title(\"Standard JPDA\")\n",
    "\n",
    "axm2 = multi_fig.add_subplot(2, 1, 2)\n",
    "axm2.set_xlabel(\"$x$\")\n",
    "axm2.set_ylabel(\"$y$\")\n",
    "axm2.set_ylim(0, 25)\n",
    "axm2.set_xlim(0, 25)\n",
    "axm2.set_title(\"JPDA with EHM\")\n",
    "\n",
    "# Plot ground truth.\n",
    "for truth in truths:\n",
    "    axm.plot([state.state_vector[0] for state in truth],\n",
    "             [state.state_vector[2] for state in truth],\n",
    "             linestyle=\"--\",)\n",
    "    axm2.plot([state.state_vector[0] for state in truth],\n",
    "             [state.state_vector[2] for state in truth],\n",
    "             linestyle=\"--\", )\n",
    "\n",
    "# Generate measurements.\n",
    "all_measurements = []\n",
    "\n",
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4,\n",
    "    mapping=(0, 2),\n",
    "    noise_covar=np.array([[0.75, 0],\n",
    "                          [0, 0.75]])\n",
    "    )\n",
    "\n",
    "prob_detect = 0.9  # 90% chance of detection.\n",
    "\n",
    "for k in range(20):\n",
    "    measurement_set = set()\n",
    "\n",
    "    for truth in truths:\n",
    "        # Generate actual detection from the state with a 10% chance that no detection is received.\n",
    "        if np.random.rand() <= prob_detect:\n",
    "            measurement = measurement_model.function(truth[k], noise=True)\n",
    "            measurement_set.add(TrueDetection(state_vector=measurement,\n",
    "                                              groundtruth_path=truth,\n",
    "                                              timestamp=truth[k].timestamp))\n",
    "\n",
    "        # Generate clutter at this time-step\n",
    "        truth_x = truth[k].state_vector[0]\n",
    "        truth_y = truth[k].state_vector[2]\n",
    "        for _ in range(np.random.randint(30)):\n",
    "            x = uniform.rvs(truth_x - 10, 20)\n",
    "            y = uniform.rvs(truth_y - 10, 20)\n",
    "            measurement_set.add(Clutter(np.array([[x], [y]]), timestamp=truth[k].timestamp))\n",
    "    all_measurements.append(measurement_set)\n",
    "\n",
    "# Plot measurements.\n",
    "for set_ in all_measurements:\n",
    "    # Plot actual detections.\n",
    "    axm.scatter([state.state_vector[0] for state in set_ if isinstance(state, TrueDetection)],\n",
    "                [state.state_vector[1] for state in set_ if isinstance(state, TrueDetection)],\n",
    "                color='g')\n",
    "    # Plot clutter.\n",
    "    axm.scatter([state.state_vector[0] for state in set_ if isinstance(state, Clutter)],\n",
    "                [state.state_vector[1] for state in set_ if isinstance(state, Clutter)],\n",
    "                color='y',\n",
    "                marker='2')\n",
    "    # Plot actual detections.\n",
    "    axm2.scatter([state.state_vector[0] for state in set_ if isinstance(state, TrueDetection)],\n",
    "                [state.state_vector[1] for state in set_ if isinstance(state, TrueDetection)],\n",
    "                color='g')\n",
    "    # Plot clutter.\n",
    "    axm2.scatter([state.state_vector[0] for state in set_ if isinstance(state, Clutter)],\n",
    "                [state.state_vector[1] for state in set_ if isinstance(state, Clutter)],\n",
    "                color='y',\n",
    "                marker='2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor and Updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.predictor.kalman import KalmanPredictor\n",
    "predictor = KalmanPredictor(transition_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.updater.kalman import KalmanUpdater\n",
    "updater = KalmanUpdater(measurement_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial hypotheses are calculated (per track) in the same manner as the PDA.\n",
    "Therefore, in Stone Soup, the JPDA filter uses the :class:`~.PDAHypothesiser` to create these\n",
    "hypotheses.\n",
    "Unlike the :class:`~.PDA` data associator, in Stone Soup, the :class:`~.JPDA` associator takes\n",
    "this collection of hypotheses and adjusts their weights according to the method described above,\n",
    "before returning key-value pairs of tracks and detections to be associated with them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.hypothesiser.probability import PDAHypothesiser\n",
    "# This doesn't need to be created again, but for the sake of visualising the process, it has been\n",
    "# added.\n",
    "hypothesiser = PDAHypothesiser(predictor=predictor,\n",
    "                               updater=updater,\n",
    "                               clutter_spatial_density=0.125,\n",
    "                               prob_detect=prob_detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.metricgenerator.manager import SimpleManager\n",
    "from stonesoup.metricgenerator.ospametric import OSPAMetric\n",
    "from stonesoup.measures import Euclidean\n",
    "\n",
    "ospa_generator = OSPAMetric(c=10, p=1, measure=Euclidean([0, 2]))\n",
    "\n",
    "# Metric manager for standard JPDA\n",
    "metric_manager_jpda = SimpleManager([ospa_generator])\n",
    "\n",
    "# Metric manager for JPDA with EHM\n",
    "metric_manager_jpda_ehm = SimpleManager([ospa_generator])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.state import GaussianState\n",
    "from stonesoup.types.track import Track\n",
    "\n",
    "prior1 = GaussianState([[0], [1], [0], [1]], np.diag([1.5, 0.5, 1.5, 0.5]), timestamp=start_time)\n",
    "prior2 = GaussianState([[0], [1], [20], [-1]], np.diag([1.5, 0.5, 1.5, 0.5]), timestamp=start_time)\n",
    "\n",
    "# Track priors for standard JPDA\n",
    "tracks_jpda = {Track([prior1]), Track([prior2])}\n",
    "\n",
    "# Track priors for JPDA with EHM\n",
    "tracks_jpda_ehm = {Track([prior1]), Track([prior2])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the standard JPDA filter\n",
    "-----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.array import StateVectors\n",
    "from stonesoup.functions import gm_reduce_single\n",
    "from stonesoup.types.update import GaussianStateUpdate\n",
    "from stonesoup.dataassociator.probability import JPDA\n",
    "\n",
    "data_associator = JPDA(hypothesiser=hypothesiser)\n",
    "\n",
    "s = datetime.now()\n",
    "for n, measurements in enumerate(all_measurements):\n",
    "    hypotheses = data_associator.associate(tracks_jpda,\n",
    "                                           measurements,\n",
    "                                           start_time + timedelta(seconds=n))\n",
    "\n",
    "    # Loop through each track, performing the association step with weights adjusted according to\n",
    "    # JPDA.\n",
    "    for track in tracks_jpda:\n",
    "        track_hypotheses = hypotheses[track]\n",
    "\n",
    "        posterior_states = []\n",
    "        posterior_state_weights = []\n",
    "        for hypothesis in track_hypotheses:\n",
    "            if not hypothesis:\n",
    "                posterior_states.append(hypothesis.prediction)\n",
    "            else:\n",
    "                posterior_state = updater.update(hypothesis)\n",
    "                posterior_states.append(posterior_state)\n",
    "            posterior_state_weights.append(hypothesis.probability)\n",
    "\n",
    "        means = StateVectors([state.state_vector for state in posterior_states])\n",
    "        covars = np.stack([state.covar for state in posterior_states], axis=2)\n",
    "        weights = np.asarray(posterior_state_weights)\n",
    "\n",
    "        # Reduce mixture of states to one posterior estimate Gaussian.\n",
    "        post_mean, post_covar = gm_reduce_single(means, covars, weights)\n",
    "\n",
    "        # Add a Gaussian state approximation to the track.\n",
    "        track.append(GaussianStateUpdate(\n",
    "            post_mean, post_covar,\n",
    "            track_hypotheses,\n",
    "            track_hypotheses[0].measurement.timestamp))\n",
    "    \n",
    "    metric_manager_jpda.add_data(\n",
    "        truths, tracks_jpda, measurements,\n",
    "        overwrite=False,  # Don't overwrite, instead add above as additional data\n",
    "    )\n",
    "diff_jpda = datetime.now() - s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the JPDA with EHM filter\n",
    "------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyehm.plugins.stonesoup import JPDAWithEHM\n",
    "\n",
    "data_associator = JPDAWithEHM(hypothesiser=hypothesiser)\n",
    "\n",
    "s = datetime.now()\n",
    "for n, measurements in enumerate(all_measurements):\n",
    "    hypotheses = data_associator.associate(tracks_jpda_ehm,\n",
    "                                           measurements,\n",
    "                                           start_time + timedelta(seconds=n))\n",
    "\n",
    "    # Loop through each track, performing the association step with weights adjusted according to\n",
    "    # JPDA.\n",
    "    for track in tracks_jpda_ehm:\n",
    "        track_hypotheses = hypotheses[track]\n",
    "\n",
    "        posterior_states = []\n",
    "        posterior_state_weights = []\n",
    "        for hypothesis in track_hypotheses:\n",
    "            if not hypothesis:\n",
    "                posterior_states.append(hypothesis.prediction)\n",
    "            else:\n",
    "                posterior_state = updater.update(hypothesis)\n",
    "                posterior_states.append(posterior_state)\n",
    "            posterior_state_weights.append(hypothesis.probability)\n",
    "\n",
    "        means = StateVectors([state.state_vector for state in posterior_states])\n",
    "        covars = np.stack([state.covar for state in posterior_states], axis=2)\n",
    "        weights = np.asarray(posterior_state_weights)\n",
    "\n",
    "        # Reduce mixture of states to one posterior estimate Gaussian.\n",
    "        post_mean, post_covar = gm_reduce_single(means, covars, weights)\n",
    "\n",
    "        # Add a Gaussian state approximation to the track.\n",
    "        track.append(GaussianStateUpdate(\n",
    "            post_mean, post_covar,\n",
    "            track_hypotheses,\n",
    "            track_hypotheses[0].measurement.timestamp))\n",
    "    \n",
    "    metric_manager_jpda_ehm.add_data(\n",
    "        truths, tracks_jpda_ehm, measurements,\n",
    "        overwrite=False,  # Don't overwrite, instead add above as additional data\n",
    "    )\n",
    "    \n",
    "    \n",
    "diff_jpda_ehm = datetime.now() - s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the resulting tracks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in tracks_jpda:\n",
    "    # Plot track.\n",
    "    axm.plot([state.state_vector[0, 0] for state in track[1:]],  # Skip plotting the prior\n",
    "             [state.state_vector[2, 0] for state in track[1:]],\n",
    "             marker=\".\")\n",
    "\n",
    "# Plot ellipses representing the gaussian estimate state at each update.\n",
    "from matplotlib.patches import Ellipse\n",
    "for track in tracks_jpda:\n",
    "    for state in track[1:]:  # Skip the prior\n",
    "        w, v = np.linalg.eig(measurement_model.matrix()@state.covar@measurement_model.matrix().T)\n",
    "        max_ind = np.argmax(w)\n",
    "        min_ind = np.argmin(w)\n",
    "        orient = np.arctan2(v[1, max_ind], v[0, max_ind])\n",
    "        ellipse = Ellipse(xy=state.state_vector[(0, 2), 0],\n",
    "                          width=2*np.sqrt(w[max_ind]),\n",
    "                          height=2*np.sqrt(w[min_ind]),\n",
    "                          angle=np.rad2deg(orient),\n",
    "                          alpha=0.2)\n",
    "        axm.add_artist(ellipse)\n",
    "\n",
    "for track in tracks_jpda_ehm:\n",
    "    # Plot track.\n",
    "    axm2.plot([state.state_vector[0, 0] for state in track[1:]],  # Skip plotting the prior\n",
    "             [state.state_vector[2, 0] for state in track[1:]],\n",
    "             marker=\".\")\n",
    "\n",
    "# Plot ellipses representing the gaussian estimate state at each update.\n",
    "from matplotlib.patches import Ellipse\n",
    "for track in tracks_jpda_ehm:\n",
    "    for state in track[1:]:  # Skip the prior\n",
    "        w, v = np.linalg.eig(measurement_model.matrix()@state.covar@measurement_model.matrix().T)\n",
    "        max_ind = np.argmax(w)\n",
    "        min_ind = np.argmin(w)\n",
    "        orient = np.arctan2(v[1, max_ind], v[0, max_ind])\n",
    "        ellipse = Ellipse(xy=state.state_vector[(0, 2), 0],\n",
    "                          width=2*np.sqrt(w[max_ind]),\n",
    "                          height=2*np.sqrt(w[min_ind]),\n",
    "                          angle=np.rad2deg(orient),\n",
    "                          alpha=0.2)\n",
    "        axm2.add_artist(ellipse)\n",
    "multi_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Compare computation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard JPDA: {} seconds\".format(diff_jpda.total_seconds()))\n",
    "print(\"JPDA with EHM: {} seconds\".format(diff_jpda_ehm.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for standard JPDA\n",
    "metrics_jpda = metric_manager_jpda.generate_metrics()\n",
    "ospa_metric_jpda = {metric for metric in metrics_jpda if metric.title == \"OSPA distances\"}.pop()\n",
    "\n",
    "# Metrics for JPDA with EHM\n",
    "metrics_jpda_ehm = metric_manager_jpda_ehm.generate_metrics()\n",
    "ospa_metric_jpda_ehm = {metric for metric in metrics_jpda_ehm if metric.title == \"OSPA distances\"}.pop()\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot([i.timestamp for i in ospa_metric_jpda.value], [i.value for i in ospa_metric_jpda.value], 'x-', label='Standard JPDA')\n",
    "ax.plot([i.timestamp for i in ospa_metric_jpda_ehm.value], [i.value for i in ospa_metric_jpda_ehm.value], '*--', label='JPDA with EHM')\n",
    "ax.set_ylabel(\"OSPA distance\")\n",
    "ax.tick_params(labelbottom=False)\n",
    "_ = ax.set_xlabel(\"Time\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------\n",
    "1. Bar-Shalom Y, Daum F, Huang F 2009, The Probabilistic Data Association Filter, IEEE Control Systems Magazine\n",
    "2. Simon Maskell, Mark Briers, Robert Wright, \"Fast mutual exclusion,\" Proc. SPIE 5428, Signal and Data Processing of Small Targets 2004\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehm",
   "language": "python",
   "name": "ehm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
